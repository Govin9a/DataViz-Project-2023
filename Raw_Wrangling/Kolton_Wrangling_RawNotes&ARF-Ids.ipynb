{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7227609c-aca7-4854-98aa-0c0a6b6a336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import json\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e794f92b-bf3a-475a-ab0a-ea5272fb081c",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ba8ed2-14b8-48c4-930e-c84747286244",
   "metadata": {},
   "source": [
    "## Sqlite3 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9f2912-1dfc-4225-a9f0-1d1b9a0e76f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'F:/mimic-iii-clinical-database-1.4/mimic3.db'\n",
    "sqliteConnection = sqlite3.connect(db_path)\n",
    "mimiciii = sqliteConnection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "096f5c5d-e682-48a6-a238-db6f07ebd564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_df_from_files(path, filter_for=[]):\n",
    "    hadm_ids = []\n",
    "    texts = []\n",
    "    \n",
    "    if filter_for:\n",
    "        files = [file + '.txt' for file in filter_for]\n",
    "    else:\n",
    "        files = os.listdir(path)\n",
    "        \n",
    "    for file in files:\n",
    "        try:\n",
    "            with open(path + file) as f:\n",
    "                    text = f.read()\n",
    "        except:\n",
    "            print('Something went wrong with', file)\n",
    "            continue\n",
    "        hadm_id = file[:-4]\n",
    "        \n",
    "        hadm_ids.append(hadm_id)\n",
    "        texts.append(text)\n",
    "            \n",
    "    return pd.DataFrame({'HADM_ID': hadm_ids, 'TEXT': texts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d8fa127-b11c-406f-9c6e-7ebde6fd4853",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>----CATEGORY:Discharge summary----\\n\\n--NEW:Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>----CATEGORY:Discharge summary----\\n\\n--NEW:Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100006</td>\n",
       "      <td>----CATEGORY:Discharge summary----\\n\\n--NEW:Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100007</td>\n",
       "      <td>----CATEGORY:Discharge summary----\\n\\n--NEW:Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100009</td>\n",
       "      <td>----CATEGORY:Discharge summary----\\n\\n--NEW:Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100010</td>\n",
       "      <td>----CATEGORY:Discharge summary----\\n\\n--NEW:Re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HADM_ID                                               TEXT\n",
       "0  100001  ----CATEGORY:Discharge summary----\\n\\n--NEW:Re...\n",
       "1  100003  ----CATEGORY:Discharge summary----\\n\\n--NEW:Re...\n",
       "2  100006  ----CATEGORY:Discharge summary----\\n\\n--NEW:Re...\n",
       "3  100007  ----CATEGORY:Discharge summary----\\n\\n--NEW:Re...\n",
       "4  100009  ----CATEGORY:Discharge summary----\\n\\n--NEW:Re...\n",
       "5  100010  ----CATEGORY:Discharge summary----\\n\\n--NEW:Re..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_for = ['100001', '100003', '100006', '100007', '100009', '100010']\n",
    "\n",
    "get_df_from_files('all_notes/', filter_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8515a28a-da43-4407-9d0c-cf5d964c99e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def condense_notes(admission_df, noteevents_df):\n",
    "    admission_ids = admission_df.HADM_ID.unique()\n",
    "    admission_ids.sort()\n",
    "\n",
    "    condensed_notes = pd.DataFrame()\n",
    "    condensed_notes['HADM_ID'] = admission_ids\n",
    "    notes_list = []\n",
    "    \n",
    "    for adm_id in tqdm(admission_ids):\n",
    "        curr_adm = noteevents[noteevents.HADM_ID == adm_id]\n",
    "        categories = curr_adm.CATEGORY.unique()\n",
    "        curr_chart = ''\n",
    "        \n",
    "        for category in categories:\n",
    "            curr_chart += '----CATEGORY: ' + category + '----\\n\\n'\n",
    "            curr_category_notes = curr_adm[curr_adm.CATEGORY == category][['DESCRIPTION', 'TEXT']]\n",
    "            curr_descriptions = curr_category_notes.DESCRIPTION.to_list()\n",
    "            curr_notes = curr_category_notes.TEXT.to_list()\n",
    "\n",
    "            for i in range(len(curr_descriptions)):\n",
    "                curr_chart += '--NEW: ' + curr_descriptions[i] + '--\\n'\n",
    "                curr_chart += curr_notes[i] + '\\n'\n",
    "\n",
    "            curr_chart += '\\n\\n'\n",
    "\n",
    "        notes_list.append(curr_chart)\n",
    "    condensed_notes['TEXT'] = notes_list\n",
    "    \n",
    "    return condensed_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0a0796-c2b0-43a8-9139-6e53ec641c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_dot_zero(value):\n",
    "    if pd.notna(value):\n",
    "        return str(int(float(value)))\n",
    "    else:\n",
    "        return '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7277d1fd-90be-44b5-89a0-a078b12dd9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_names(cursor, table_name):\n",
    "    cursor.execute(f\"\"\"\n",
    "    SELECT sql FROM sqlite_master WHERE name='{table_name}';\n",
    "    \"\"\")\n",
    "    \n",
    "    res = mimiciii.fetchall()\n",
    "    cols = re.findall(r'\\\"\\w+\\\"', res[0][0])\n",
    "    return [x[1:-1] for x in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81da2e90-80b8-45da-b26a-be01e8af5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_table_from_db(cursor, table_name, num_rows='*', skip_cols=[]):\n",
    "    '''\n",
    "    cursor: sqliteConnection cursor object\n",
    "    table_name: name of table to get from cursor db\n",
    "    num_rows: number of rows to retrieve (or '*' for all rows)\n",
    "    skip_cols: list of columns to skip in the retrieval\n",
    "    '''\n",
    "    col_names = get_col_names(cursor, table_name)\n",
    "    \n",
    "    use_cols = [col for col in col_names if col not in skip_cols]\n",
    "    \n",
    "    if num_rows == '*':\n",
    "        query = f'''select {', '.join(use_cols)} from {table_name};'''\n",
    "    else:\n",
    "        query = f'''select {', '.join(use_cols)} from {table_name} limit {num_rows};'''\n",
    "        \n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    return pd.DataFrame(rows, columns=use_cols, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b0a2aa-fab5-4518-874f-af3ff9e77646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tables_list_from_db(cursor):\n",
    "    cursor.execute(\"\"\"\n",
    "    select name from sqlite_master where type='table';\n",
    "    \"\"\")\n",
    "    table_names = [table[0] for table in cursor.fetchall()]\n",
    "    return table_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fea10f-d3c4-4879-896b-4e5b982e312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int(x):\n",
    "    if not x or np.isnan(x):\n",
    "        return 0\n",
    "    return int(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9f75b0-f876-40d1-bc33-0b14d07d313c",
   "metadata": {},
   "source": [
    "Steps for dataset:\n",
    "\n",
    "1.  filter ADMISSIONS table for ARF-related diagnoses\n",
    "2. filter drg table for ARF-related DRGs\n",
    "3. join previous two tables\n",
    "4. remove any similar but not ARF rows\n",
    "5. join on HADM_ID other tables: NOTEEVENTS, PRESCRIPTIONS, LABEVENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80733612-6d96-45ac-8e8f-e32c7a0ed202",
   "metadata": {},
   "source": [
    "#### 1. filter ADMISSIONS table for ARF-related diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c9f7e5-af8b-4446-8305-c5721d9838a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all admissions\n",
    "admission = get_df_from_table_from_db(mimiciii, 'admissions')\n",
    "admission = admission.apply(lambda x: x.astype(str).str.upper())\n",
    "#admission.HADM_ID = admission.HADM_ID.astype('int64')\n",
    "admission.SUBJECT_ID = admission.SUBJECT_ID.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f0d56-3425-44b4-9e46-1582c7d40569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#filter for ARF-related diagnoses\n",
    "arf_adm= admission[admission.DIAGNOSIS.str.contains('RESPIRATORY FAILURE') | admission.DIAGNOSIS.str.contains('RESP. FAILURE')  | admission.DIAGNOSIS.str.contains('RESP FAILURE')]\n",
    "to_exclude = ['CHRONIC RESPIRATORY FAILURE;AIRWAY OBSTRUCTION', 'CHRONIC RESPIRATORY FAILURE', 'CHRONIC RESPIRATORY FAILURE; TRAC OBSTRUCTED AIRWAY']\n",
    "arf_adm = arf_adm[~arf_adm.DIAGNOSIS.isin(to_exclude)]\n",
    "arf_adm = arf_adm[arf_adm.HADM_ID != 0]\n",
    "\n",
    "arf_adm_ID = arf_adm.HADM_ID.to_list()\n",
    "\n",
    "arf_adm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a7e47a-230c-4ab4-9db0-b50688af9cfe",
   "metadata": {},
   "source": [
    "#### 2. filter drg table for ARF-related DRGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1ccfba-3d57-4f28-bffe-a13f1a0765cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all drg codes\n",
    "drgcodes = get_df_from_table_from_db(mimiciii, 'drgcodes')\n",
    "drgcodes.DESCRIPTION = drgcodes.DESCRIPTION.astype(str)\n",
    "\n",
    "#filter for ARF\n",
    "#arf_drg = drgcodes[drgcodes.DESCRIPTION.str.contains('RESPIRATORY FAILURE') | ((drgcodes.DRG_CODE == 193) & (drgcodes.DRG_TYPE == 'MS'))]\n",
    "arf_drg = drgcodes[drgcodes.DESCRIPTION.str.contains('RESPIRATORY FAILURE')]\n",
    "arf_drg = arf_drg[arf_drg.HADM_ID != 0]\n",
    "\n",
    "arf_drg_ID = arf_drg.HADM_ID.to_list()\n",
    "\n",
    "arf_drg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5fb350-b48a-49e9-82f0-b733aeeeecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arf_adm.shape)\n",
    "print(arf_drg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626d6862-57b8-4778-8a14-274fd7ac9279",
   "metadata": {},
   "source": [
    "#### 3. join previous two tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e446db93-b62a-4ee6-8b18-d4d0a1707a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hadm_ids = list(set(arf_drg_ID + arf_adm_ID))\n",
    "print(len(hadm_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea1c229-da54-4c4e-affb-4104d7bbc4ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('arf_hadm_ids.json', 'w') as j_file:\n",
    "    json.dump(hadm_ids, j_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8191e402-7402-424b-b85d-4012390b2d88",
   "metadata": {},
   "source": [
    "#### 4. remove any similar but not ARF rows\n",
    "\n",
    "already done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52506bef-e2c0-474a-bfdb-92dfa9cc3ed0",
   "metadata": {},
   "source": [
    "#### 5. join on HADM_ID other tables: NOTEEVENTS, PRESCRIPTIONS, LABEVENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f099ad-bec4-4729-95ff-641a84fba578",
   "metadata": {},
   "source": [
    "#### noteevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce22d102-e816-48bd-b7cd-d17caf82e3d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "noteevents = get_df_from_table_from_db(mimiciii, 'noteevents')\n",
    "noteevents.HADM_ID = noteevents.HADM_ID.apply(fix_dot_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ae7195-16b6-4ff4-978c-9f7ea711d92b",
   "metadata": {},
   "source": [
    "##### compile all notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c0834-e529-4b6d-b49a-734fe21f23af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condensed_notes = condense_notes(admission, noteevents)\n",
    "for index, row in condensed_notes.iterrows():\n",
    "    with open(f'all_notes/{row[\"HADM_ID\"]}.txt', 'w') as f:\n",
    "        f.write(row['TEXT'])\n",
    "\n",
    "condensed_notes.to_csv('all_notes_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef25adb-94f9-4550-a620-a2cf89ea94fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condensed_notes = pd.read_csv('all_notes_raw.csv')\n",
    "condensed_notes.TEXT  = condensed_notes.TEXT.astype(str)\n",
    "condensed_notes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86814f7-daa7-42ef-8629-c75859a04206",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_notes(df, file_to_write, subset=False, start_at=0):\n",
    "    df.TEXT = df.TEXT.astype(str)\n",
    "    if subset:\n",
    "        notes_list = df.TEXT.to_list()[:1000]\n",
    "        hadm_ids = df.HADM_ID.to_list()[:1000]\n",
    "    else:\n",
    "        notes_list = df.TEXT.to_list()[start_at:]\n",
    "        hadm_ids = df.HADM_ID.to_list()\n",
    "    \n",
    "    #filtered_notes = []\n",
    "    stop_words = set(stopwords.words('english') + ['*'])\n",
    "    \n",
    "    num_notes = len(notes_list)\n",
    "    with open(file_to_write, 'a', newline='') as file:\n",
    "        csv_writer = csv.writer(file)\n",
    "        for i, note in tqdm(enumerate(notes_list), total=num_notes):\n",
    "            tokens = word_tokenize(note)\n",
    "            filtered_text = ' '.join([word for word in tokens if word.lower() not in stop_words])\n",
    "            \n",
    "            csv_writer.writerow([str(hadm_ids[i]), filtered_text])\n",
    "            \n",
    "            with open('log.txt', 'w') as log:\n",
    "                log.write(str(int(i) + int(start_at)))\n",
    "    \n",
    "try:\n",
    "    with open('log.txt', 'r') as file:\n",
    "        start_at = file.read()\n",
    "except:\n",
    "    start_at = 0\n",
    "\n",
    "filter_notes(condensed_notes, file_to_write='notes_filtered_condensed.csv', start_at=int(start_at))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a5a252-57a2-450e-a9b7-9638e2754b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get arf notes list or subject id\n",
    "tmp1 = pd.merge(arf_adm, noteevents, on='HADM_ID', how='left').HADM_ID.to_list()\n",
    "tmp2 = pd.merge(arf_drg, noteevents, on='HADM_ID', how='left').HADM_ID.to_list()\n",
    "notes_set = set(tmp1 + tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebc4695-ac8b-4846-b448-ca6f7323aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arf notes\n",
    "arf_notes = noteevents[noteevents.HADM_ID.isin(notes_set)]\n",
    "print(arf_notes.shape)\n",
    "arf_notes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56606435-6268-4f40-b435-cca53775784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine admission notes into one\n",
    "\n",
    "arf_admission_ids = pd.unique(arf_notes.HADM_ID)\n",
    "arf_admission_ids.sort()\n",
    "\n",
    "condensed_arf_notes = pd.DataFrame()\n",
    "\n",
    "condensed_arf_notes['HADM_ID'] = arf_admission_ids\n",
    "\n",
    "arf_notes_list = []\n",
    "\n",
    "for adm_id in tqdm(arf_admission_ids):\n",
    "    curr_adm = arf_notes[arf_notes.HADM_ID == adm_id]\n",
    "    categories = pd.unique(curr_adm.CATEGORY)\n",
    "    curr_chart = ''\n",
    "    \n",
    "    for category in categories:\n",
    "        curr_chart += '----CATEGORY:' + category + '----\\n\\n'\n",
    "        curr_category_notes = curr_adm[curr_adm.CATEGORY == category][['DESCRIPTION', 'TEXT']]\n",
    "        curr_descriptions = curr_category_notes.DESCRIPTION.to_list()\n",
    "        curr_notes = curr_category_notes.TEXT.to_list()\n",
    "\n",
    "        for i in range(len(curr_descriptions)):\n",
    "            curr_chart += '--NEW:' + curr_descriptions[i] + '--\\n'\n",
    "            curr_chart += curr_notes[i] + '\\n'\n",
    "\n",
    "        curr_chart += '\\n\\n'\n",
    "    \n",
    "    arf_notes_list.append(curr_chart)\n",
    "    \n",
    "condensed_arf_notes['TEXT'] = arf_notes_list\n",
    "print(len(condensed_arf_notes))\n",
    "print(condensed_arf_notes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb19f3-1505-4de8-a19b-eecd39fba77c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condensed_arf_notes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891ca56c-2f69-4b78-8b7f-b068e961acbd",
   "metadata": {},
   "source": [
    "#combine admission notes into one\n",
    "single_adm = arf_notes[arf_notes.HADM_ID == 134727]\n",
    "\n",
    "categories = pd.unique(single_adm.CATEGORY)\n",
    "\n",
    "curr_chart = ''\n",
    "for category in categories:\n",
    "    curr_chart += '----CATEGORY:' + category + '----\\n\\n'\n",
    "    curr_category_notes = single_adm[single_adm.CATEGORY == category][['DESCRIPTION', 'TEXT']]\n",
    "    curr_descriptions = curr_category_notes.DESCRIPTION.to_list()\n",
    "    curr_notes = curr_category_notes.TEXT.to_list()\n",
    "        \n",
    "    for i in range(len(curr_descriptions)):\n",
    "        curr_chart += '--NEW:' + curr_descriptions[i] + '--\\n'\n",
    "        curr_chart += curr_notes[i] + '\\n'\n",
    "        \n",
    "    curr_chart += '\\n\\n'\n",
    "\n",
    "print(curr_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7b05ce-743d-43a9-9419-8625a306021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-proc arf notes\n",
    "arf_notes_list = condensed_arf_notes.TEXT.to_list()\n",
    "\n",
    "filtered_notes = []\n",
    "stop_words = set(stopwords.words('english') + ['*'])\n",
    "\n",
    "for note in tqdm(arf_notes_list):\n",
    "    tokens = word_tokenize(note)\n",
    "    filtered_text = ' '.join([word for word in tokens if word.lower() not in stop_words])\n",
    "    filtered_notes.append(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c0b9d-fb27-4e8f-8e7e-63a9b534a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_arf_notes['FILTERED_TEXT'] = filtered_notes\n",
    "condensed_arf_notes.to_csv('arf_notes_filtered_condensed.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db16db2-273a-4765-81f4-5ebd03196b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(condensed_arf_notes.TEXT.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9941c27f-86b5-42c0-8cef-08b8a91c588f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "master_df = pd.merge(arf_adm, condensed_arf_notes, on='HADM_ID', how='inner')\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fcba69-a28b-47cd-aeed-579c732082b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "noteevents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabd0fa8-90c9-414d-b863-2728671cdd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_chart = septic_notes.iloc[0].FILTERED_TEXT\n",
    "\n",
    "template = '''\n",
    "Question: {question}\n",
    "\n",
    "Clinical Chart: {chart}\n",
    "\n",
    "Answer: Let's think step by step: \n",
    "'''\n",
    "\n",
    "question = '''Given is some text found in a clinical chart. Is there sign or indication that this patient had sepsis?'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['question', 'chart'],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191672f6-49bb-4cfb-8290-52abe05472ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f8ea4c-8087-4523-bc13-d74ebf281c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'sepsis' in sample_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5087767e-2c1c-47a7-afc9-a81c091e0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_chart = septic_notes.iloc[0].FILTERED_TEXT\n",
    "llm_chain = LLMChain(prompt=prompt,\n",
    "                     llm=ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55209101-6763-4529-8728-45cd57ca4e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_chart = septic_notes.iloc[0].FILTERED_TEXT[:1000]\n",
    "llm_chain = LLMChain(prompt=prompt,\n",
    "                     llm=HuggingFaceHub(repo_id='google/flan-t5-xxl',\n",
    "                                        model_kwargs={\n",
    "                                            'temperature': 1e-5\n",
    "                                        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6b60d-8c51-4c25-8b44-57276ff16e29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(llm_chain.run(question=question, chart=sample_chart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb344b1-a66b-4173-a128-33172cf8ed7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b252d1a-758f-49ef-b8d2-23b501e981d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea2cf55-3db4-4189-b0c7-52e998daab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "        template=template,\n",
    "    input_variables=['question']\n",
    ")\n",
    "\n",
    "# user question\n",
    "question = \"Which NFL team won the Super Bowl in the 2010 season?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcf5dfc-fa0a-43ab-aac5-94a56d2662a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Hub LLM\n",
    "hub_llm = HuggingFaceHub(\n",
    "        repo_id='google/flan-t5-xxl',\n",
    "    model_kwargs={'temperature':1e-10}\n",
    ")\n",
    "\n",
    "# create prompt template > LLM chain\n",
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=hub_llm\n",
    ")\n",
    "\n",
    "# ask the user question about NFL 2010\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af92b5f-35fd-46f2-80e0-e5668e02c770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea977e5-a6c6-4292-b20b-fe0132146999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad57274-6d1e-4abc-9332-caec13e07e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd566603-71a0-4cb0-bafc-1e6e11a3b195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri('sqlite:///F:/mimic-iii-clinical-database-1.4/mimic3.db')\n",
    "db_chain = SQLDatabaseChain(llm=HuggingFaceHub(repo_id='google/flan-t5-xxl',\n",
    "                                        model_kwargs={\n",
    "                                            'temperature': .01\n",
    "                                        }),\n",
    "                            database=db,\n",
    "                            verbose=True)\n",
    "\n",
    "db_chain.run(\"How many tables are there?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
