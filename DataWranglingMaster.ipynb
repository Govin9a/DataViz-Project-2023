{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ce3a403-0006-4fb4-914f-2e503b770a7f",
   "metadata": {},
   "source": [
    "# Data Collection Master Notebook\n",
    "\n",
    "This dataset primarily revolves around the lab events and free notes found in MIMIC-III, located in the labeevents and noteevents tables in the database.\n",
    "\n",
    "This notebook shares our data collection methods used in each of our visualizations. Each of the group members curated a dataset to be used and each are outlined as below. However, running the notebook is not recommended as some processes take a long time to run. Just use the finished file shared in the 'Data/' folder located in this GitHub repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f723774b-5bb2-4c6b-822a-8754ff8e1115",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311db286-0c2e-4f8c-a936-f747c67d3e9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb649a37-5c16-4f40-a4f1-62beede418a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021277ff-4b50-47bf-94f9-6a772f8217d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Sqlite3 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f23a11-5838-448c-922a-29eeee42ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative path to where the mimic3.db file is\n",
    "db_path = '/mnt/f/mimic-iii-clinical-database-1.4/mimic3.db'\n",
    "#connection object to db\n",
    "sqliteConnection = sqlite3.connect(db_path)\n",
    "#cursor/pointer\n",
    "mimiciii = sqliteConnection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1862184d-0b98-40be-9b8f-2a57a3759876",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e9df21-91e5-4b09-a60d-d8640bf56c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_names(cursor, table_name):\n",
    "    '''\n",
    "    Retrieves the column names for a table in a sqlite3 db.\n",
    "    ------\n",
    "    cursor: sqliteConnection cursor object\n",
    "    table_name: table_name to get column names for\n",
    "    '''\n",
    "    cursor.execute(f\"\"\"\n",
    "    SELECT sql FROM sqlite_master WHERE name='{table_name}';\n",
    "    \"\"\")\n",
    "    \n",
    "    res = mimiciii.fetchall()\n",
    "    cols = re.findall(r'\\\"\\w+\\\"', res[0][0])\n",
    "    return [x[1:-1] for x in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50cdb4b5-5274-4883-8cab-6f763386a42a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def condense_notes(admission_df, noteevents_df):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    admission_ids = admission_df.HADM_ID.unique()\n",
    "    admission_ids.sort()\n",
    "\n",
    "    condensed_notes = pd.DataFrame()\n",
    "    condensed_notes['HADM_ID'] = admission_ids\n",
    "    notes_list = []\n",
    "    \n",
    "    for adm_id in tqdm(admission_ids):\n",
    "        curr_adm = noteevents[noteevents.HADM_ID == adm_id]\n",
    "        categories = curr_adm.CATEGORY.unique()\n",
    "        curr_chart = ''\n",
    "        \n",
    "        for category in categories:\n",
    "            curr_chart += '----CATEGORY: ' + category + '----\\n\\n'\n",
    "            curr_category_notes = curr_adm[curr_adm.CATEGORY == category][['DESCRIPTION', 'TEXT']]\n",
    "            curr_descriptions = curr_category_notes.DESCRIPTION.to_list()\n",
    "            curr_notes = curr_category_notes.TEXT.to_list()\n",
    "\n",
    "            for i in range(len(curr_descriptions)):\n",
    "                curr_chart += '--NEW: ' + curr_descriptions[i] + '--\\n'\n",
    "                curr_chart += curr_notes[i] + '\\n'\n",
    "\n",
    "            curr_chart += '\\n\\n'\n",
    "\n",
    "        notes_list.append(curr_chart)\n",
    "    condensed_notes['TEXT'] = notes_list\n",
    "    \n",
    "    return condensed_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f6f34c-46a8-4dae-a3a1-d2acd009aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_table_from_db(cursor, table_name, num_rows='*', skip_cols=[]):\n",
    "    '''\n",
    "    Retreives table from sqlite3 db in form of df\n",
    "    ------\n",
    "    cursor: sqliteConnection cursor object\n",
    "    table_name: name of table to get from cursor db\n",
    "    num_rows: number of rows to retrieve (or '*' for all rows)\n",
    "    skip_cols: list of columns to skip in the retrieval\n",
    "    '''\n",
    "    col_names = get_col_names(cursor, table_name)\n",
    "    \n",
    "    use_cols = [col for col in col_names if col not in skip_cols]\n",
    "    \n",
    "    if num_rows == '*':\n",
    "        query = f'''select {', '.join(use_cols)} from {table_name};'''\n",
    "    else:\n",
    "        query = f'''select {', '.join(use_cols)} from {table_name} limit {num_rows};'''\n",
    "        \n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    return pd.DataFrame(rows, columns=use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ec5cb9-4f42-42d4-8211-1f6f1f23869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tables_list_from_db(cursor):\n",
    "    cursor.execute(\"\"\"\n",
    "    select name from sqlite-master where type='table';\n",
    "    \"\"\")\n",
    "    table_names = [table[0] for table in cursor.fetchall()]\n",
    "    return table_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4697c677-a5c9-40b0-b69c-c66e3fdc60bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get HADM_IDs associated with ARF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "491aa478-2bca-4335-9a16-99e2d13396e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all admissions\n",
    "admission = get_df_from_table_from_db(mimiciii, 'admissions')\n",
    "admission = admission.apply(lambda x: x.astype(str).str.upper())\n",
    "admission.SUBJECT_ID = admission.SUBJECT_ID.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14bc3cf3-3fe7-454f-a824-e3623a02b38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "      <th>DEATHTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>ADMISSION_LOCATION</th>\n",
       "      <th>DISCHARGE_LOCATION</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>RELIGION</th>\n",
       "      <th>MARITAL_STATUS</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>EDREGTIME</th>\n",
       "      <th>EDOUTTIME</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>HOSPITAL_EXPIRE_FLAG</th>\n",
       "      <th>HAS_CHARTEVENTS_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>104</td>\n",
       "      <td>101</td>\n",
       "      <td>175533</td>\n",
       "      <td>2196-09-26 18:36:00</td>\n",
       "      <td>2196-10-12 13:17:00</td>\n",
       "      <td>2196-10-12 13:17:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>DEAD/EXPIRED</td>\n",
       "      <td>MEDICARE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>ASIAN</td>\n",
       "      <td>2196-09-26 12:50:00</td>\n",
       "      <td>2196-09-26 18:37:00</td>\n",
       "      <td>RESPIRATORY FAILURE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>1100</td>\n",
       "      <td>886</td>\n",
       "      <td>130937</td>\n",
       "      <td>2139-03-08 10:47:00</td>\n",
       "      <td>2139-03-09 17:05:00</td>\n",
       "      <td>NONE</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>REHAB/DISTINCT PART HOSP</td>\n",
       "      <td>MEDICARE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>UNKNOWN/NOT SPECIFIED</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>RESPIRATORY FAILURE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>835</td>\n",
       "      <td>679</td>\n",
       "      <td>156345</td>\n",
       "      <td>2141-10-19 14:58:00</td>\n",
       "      <td>2141-10-24 11:30:00</td>\n",
       "      <td>NONE</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>REHAB/DISTINCT PART HOSP</td>\n",
       "      <td>MEDICARE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>JEWISH</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2141-10-19 10:21:00</td>\n",
       "      <td>2141-10-19 15:08:00</td>\n",
       "      <td>ACUTE RESPIRATORY FAILURE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>1357</td>\n",
       "      <td>1093</td>\n",
       "      <td>188758</td>\n",
       "      <td>2125-11-01 21:35:00</td>\n",
       "      <td>2125-11-06 14:25:00</td>\n",
       "      <td>NONE</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>HOME</td>\n",
       "      <td>PRIVATE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>RESPIRATORY FAILURE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>886</td>\n",
       "      <td>720</td>\n",
       "      <td>171046</td>\n",
       "      <td>2160-02-15 21:44:00</td>\n",
       "      <td>2160-04-07 13:05:00</td>\n",
       "      <td>NONE</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>SNF</td>\n",
       "      <td>MEDICARE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>RESPIRATORY FAILURE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ROW_ID  SUBJECT_ID HADM_ID            ADMITTIME            DISCHTIME  \\\n",
       "106     104         101  175533  2196-09-26 18:36:00  2196-10-12 13:17:00   \n",
       "613    1100         886  130937  2139-03-08 10:47:00  2139-03-09 17:05:00   \n",
       "682     835         679  156345  2141-10-19 14:58:00  2141-10-24 11:30:00   \n",
       "1088   1357        1093  188758  2125-11-01 21:35:00  2125-11-06 14:25:00   \n",
       "1155    886         720  171046  2160-02-15 21:44:00  2160-04-07 13:05:00   \n",
       "\n",
       "                DEATHTIME ADMISSION_TYPE         ADMISSION_LOCATION  \\\n",
       "106   2196-10-12 13:17:00      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "613                  NONE      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
       "682                  NONE      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "1088                 NONE      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
       "1155                 NONE      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
       "\n",
       "            DISCHARGE_LOCATION INSURANCE LANGUAGE  RELIGION MARITAL_STATUS  \\\n",
       "106               DEAD/EXPIRED  MEDICARE     NONE      NONE        MARRIED   \n",
       "613   REHAB/DISTINCT PART HOSP  MEDICARE     NONE      NONE           NONE   \n",
       "682   REHAB/DISTINCT PART HOSP  MEDICARE     NONE    JEWISH        MARRIED   \n",
       "1088                      HOME   PRIVATE     NONE  CATHOLIC        MARRIED   \n",
       "1155                       SNF  MEDICARE     NONE  CATHOLIC        MARRIED   \n",
       "\n",
       "                  ETHNICITY            EDREGTIME            EDOUTTIME  \\\n",
       "106                   ASIAN  2196-09-26 12:50:00  2196-09-26 18:37:00   \n",
       "613   UNKNOWN/NOT SPECIFIED                 NONE                 NONE   \n",
       "682                   WHITE  2141-10-19 10:21:00  2141-10-19 15:08:00   \n",
       "1088                  WHITE                 NONE                 NONE   \n",
       "1155                  WHITE                 NONE                 NONE   \n",
       "\n",
       "                      DIAGNOSIS HOSPITAL_EXPIRE_FLAG HAS_CHARTEVENTS_DATA  \n",
       "106         RESPIRATORY FAILURE                    1                    1  \n",
       "613         RESPIRATORY FAILURE                    0                    1  \n",
       "682   ACUTE RESPIRATORY FAILURE                    0                    1  \n",
       "1088        RESPIRATORY FAILURE                    0                    1  \n",
       "1155        RESPIRATORY FAILURE                    0                    1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter for ARF-related diagnoses\n",
    "arf_adm= admission[admission.DIAGNOSIS.str.contains('RESPIRATORY FAILURE') | admission.DIAGNOSIS.str.contains('RESP. FAILURE')  | admission.DIAGNOSIS.str.contains('RESP FAILURE')]\n",
    "to_exclude = ['CHRONIC RESPIRATORY FAILURE;AIRWAY OBSTRUCTION', 'CHRONIC RESPIRATORY FAILURE', 'CHRONIC RESPIRATORY FAILURE; TRAC OBSTRUCTED AIRWAY']\n",
    "arf_adm = arf_adm[~arf_adm.DIAGNOSIS.isin(to_exclude)]\n",
    "arf_adm = arf_adm[arf_adm.HADM_ID != 0]\n",
    "\n",
    "#get HADM_IDs for admissions associated with ARF\n",
    "arf_adm_ID = arf_adm.HADM_ID.to_list()\n",
    "\n",
    "arf_adm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bd5a679-dabc-4dfe-b82d-409609a1f9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>DRG_TYPE</th>\n",
       "      <th>DRG_CODE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>DRG_SEVERITY</th>\n",
       "      <th>DRG_MORTALITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>377</td>\n",
       "      <td>12744</td>\n",
       "      <td>116766</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>87</td>\n",
       "      <td>PULMONARY EDEMA &amp; RESPIRATORY FAILURE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>812</td>\n",
       "      <td>17125</td>\n",
       "      <td>127377</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>87</td>\n",
       "      <td>PULMONARY EDEMA &amp; RESPIRATORY FAILURE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>1803</td>\n",
       "      <td>19644</td>\n",
       "      <td>100124</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>87</td>\n",
       "      <td>PULMONARY EDEMA &amp; RESPIRATORY FAILURE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>1320</td>\n",
       "      <td>17125</td>\n",
       "      <td>105639</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>87</td>\n",
       "      <td>PULMONARY EDEMA &amp; RESPIRATORY FAILURE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>1330</td>\n",
       "      <td>19040</td>\n",
       "      <td>119678</td>\n",
       "      <td>HCFA</td>\n",
       "      <td>87</td>\n",
       "      <td>PULMONARY EDEMA &amp; RESPIRATORY FAILURE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ROW_ID  SUBJECT_ID  HADM_ID DRG_TYPE  DRG_CODE  \\\n",
       "35       377       12744   116766     HCFA        87   \n",
       "934      812       17125   127377     HCFA        87   \n",
       "1222    1803       19644   100124     HCFA        87   \n",
       "1350    1320       17125   105639     HCFA        87   \n",
       "1360    1330       19040   119678     HCFA        87   \n",
       "\n",
       "                                DESCRIPTION  DRG_SEVERITY  DRG_MORTALITY  \n",
       "35    PULMONARY EDEMA & RESPIRATORY FAILURE           NaN            NaN  \n",
       "934   PULMONARY EDEMA & RESPIRATORY FAILURE           NaN            NaN  \n",
       "1222  PULMONARY EDEMA & RESPIRATORY FAILURE           NaN            NaN  \n",
       "1350  PULMONARY EDEMA & RESPIRATORY FAILURE           NaN            NaN  \n",
       "1360  PULMONARY EDEMA & RESPIRATORY FAILURE           NaN            NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all drg codes\n",
    "drgcodes = get_df_from_table_from_db(mimiciii, 'drgcodes')\n",
    "drgcodes.DESCRIPTION = drgcodes.DESCRIPTION.astype(str)\n",
    "\n",
    "#filter for ARF\n",
    "arf_drg = drgcodes[drgcodes.DESCRIPTION.str.contains('RESPIRATORY FAILURE')]\n",
    "arf_drg = arf_drg[arf_drg.HADM_ID != 0]\n",
    "\n",
    "#get HADM_IDs for drg codes associated with ARF\n",
    "arf_drg_ID = arf_drg.HADM_ID.to_list()\n",
    "\n",
    "arf_drg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2806a807-e8e9-4c42-8013-aa53a751c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine drg and admission HADM_IDs associated with ARF\n",
    "arf_hadm_ids = list(set(arf_drg_ID + arf_adm_ID))\n",
    "\n",
    "#get all other diagnosis IDs\n",
    "other_hadm_ids = list(set([hadm_id for hadm_id in admission.HADM_ID if hadm_id not in arf_hadm_ids]))\n",
    "\n",
    "#save HADM_IDs associated with ARF to 'arf_hadm_ids.json' and OTHER diagnoses to 'other_hadm_ids.json'\n",
    "with open('Data/arf_hadm_ids.json', 'w') as j_file:\n",
    "    json.dump(arf_hadm_ids, j_file, indent=4)\n",
    "\n",
    "with open('Data/other_hadm_ids.json', 'w') as j_file:\n",
    "    json.dump(other_hadm_ids, j_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7b399a-e2e8-4df7-bd2f-766d1be52f0d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Govinda\n",
    "\n",
    "To process 'Data/DataViz_Project_Data-Frame_Govinda.csv' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e493de-812b-4b39-b1ff-0a4c8e16aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = 'Data/arf_hadm_ids.json'\n",
    "\n",
    "with open(json_path) as f:\n",
    "    arf_hadm_ids = json.load(f)\n",
    "\n",
    "# Convert 'hadm_id' values to integers\n",
    "arf_hadm_ids = list(map(int, arf_hadm_ids))\n",
    "\n",
    "# Load labevents CSV data\n",
    "#labevents_df = pd.read_csv('LABEVENTS.csv')\n",
    "labevents_df = get_df_from_table_from_db(mimiciii, 'labevents')\n",
    "\n",
    "# Handle non-finite values in 'hadm_id' column\n",
    "labevents_df['hadm_id'] = pd.to_numeric(labevents_df['hadm_id'], errors='coerce')\n",
    "labevents_df = labevents_df.dropna(subset=['hadm_id'])\n",
    "\n",
    "# Convert 'hadm_id' column to integers\n",
    "labevents_df['hadm_id'] = labevents_df['hadm_id'].astype(int)\n",
    "\n",
    "# Filter labevents_df based on arf_hadm_ids\n",
    "arf_dataframe = labevents_df[labevents_df['hadm_id'].isin(arf_hadm_ids)]\n",
    "\n",
    "# Save the filtered data to a CSV file\n",
    "arf_csv_path = 'Data/arf_dataframe.csv'\n",
    "#arf_dataframe.to_csv(arf_csv_path, index=False)\n",
    "\n",
    "# Read the arf dataset \n",
    "#arf_dataframe = pd.read_csv(arf_csv_path)\n",
    "\n",
    "# Display the number of rows in arf_dataframe\n",
    "print(\"Number of rows in arf_dataframe:\", len(arf_dataframe))\n",
    "\n",
    "print(arf_dataframe.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86386a37-1e76-452e-b668-6a9c2bbb2e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for patients with diagnoses other than ARF\n",
    "other_diagnoses = labevents_df[~labevents_df['hadm_id'].isin(arf_hadm_ids)]\n",
    "other_diagnoses\n",
    "\n",
    "# Save the data for other diagnoses to a CSV file\n",
    "other_diagnoses_csv_path = 'Data/other_diagnoses.csv'\n",
    "#other_diagnoses.to_csv(other_diagnoses_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42964e24-da2d-41b8-b9fb-0b4182f67119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop blank values in 'valuenum' column\n",
    "arf_dataframe['valuenum'].dropna(inplace=True)\n",
    "\n",
    "# Group by 'itemid' and calculate the average of 'valuenum'\n",
    "arf_average_value = arf_dataframe.groupby('itemid')['valuenum'].mean().reset_index()\n",
    "\n",
    "# Add a new column 'diagnosis' with the label 'arf' for each row\n",
    "arf_average_value['diagnosis'] = ['arf' for x in range(len(arf_average_value))]\n",
    "\n",
    "# Save the average values to a CSV file\n",
    "average_csv_path = 'Data/arf_average_value.csv'\n",
    "#arf_average_value.to_csv(average_csv_path, index=False)\n",
    "\n",
    "# Read the average values dataset\n",
    "#arf_average_value = pd.read_csv(average_csv_path)\n",
    "\n",
    "# Display the resulting DataFrame with average values\n",
    "arf_average_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b268d-d59c-4c8a-b59d-3117aa4bd7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop blank values in 'valuenum' column for other diagnoses\n",
    "other_diagnoses['valuenum'].dropna(inplace=True)\n",
    "\n",
    "# Group by 'itemid' and calculate the average of 'valuenum'\n",
    "other_diagnoses_average_value = other_diagnoses.groupby('itemid')['valuenum'].mean().reset_index()\n",
    "\n",
    "# Add a new column 'diagnosis' with the label 'other' for each row\n",
    "other_diagnoses_average_value['diagnosis'] = ['other' for x in range(len(other_diagnoses_average_value))]\n",
    "\n",
    "# Save the average values to a CSV file for other diagnoses\n",
    "other_average_csv_path = 'Data/other_diagnoses_average_value.csv'\n",
    "#other_diagnoses_average_value.to_csv(other_average_csv_path, index=False)\n",
    "\n",
    "# Read the average values dataset for other diagnoses\n",
    "#other_diagnoses_average_value = pd.read_csv(other_average_csv_path)\n",
    "\n",
    "# Display the resulting DataFrame with average values for other diagnoses\n",
    "other_diagnoses_average_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8340269-d991-468e-8a5c-542e6d60a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the ARF average values and other diagnoses average values\n",
    "combined_df = pd.concat([arf_average_value, other_diagnoses_average_value], ignore_index=True)\n",
    "combined_df = pd.pivot_table(combined_df, index='itemid', columns='diagnosis', values='valuenum', aggfunc='first')\n",
    "combined_df.reset_index(inplace=True)\n",
    "combined_df.columns.name = None\n",
    "combined_df.columns = ['itemid', 'arf', 'other']\n",
    "#Save the combined DataFrame to a CSV file\n",
    "combined_csv_path = 'Data/combined_df.csv'\n",
    "#combined_df.to_csv(combined_csv_path, index=False)\n",
    "\n",
    "# Read the combined dataset\n",
    "#combined_df = pd.read_csv(combined_csv_path)\n",
    "\n",
    "# Display the resulting combined DataFrame\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac2e0b06-d726-499e-9f0c-6e07ad853288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>ITEMID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUID</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>LOINC_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>546</td>\n",
       "      <td>51346</td>\n",
       "      <td>Blasts</td>\n",
       "      <td>Cerebrospinal Fluid (CSF)</td>\n",
       "      <td>Hematology</td>\n",
       "      <td>26447-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>547</td>\n",
       "      <td>51347</td>\n",
       "      <td>Eosinophils</td>\n",
       "      <td>Cerebrospinal Fluid (CSF)</td>\n",
       "      <td>Hematology</td>\n",
       "      <td>26451-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>548</td>\n",
       "      <td>51348</td>\n",
       "      <td>Hematocrit, CSF</td>\n",
       "      <td>Cerebrospinal Fluid (CSF)</td>\n",
       "      <td>Hematology</td>\n",
       "      <td>30398-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>549</td>\n",
       "      <td>51349</td>\n",
       "      <td>Hypersegmented Neutrophils</td>\n",
       "      <td>Cerebrospinal Fluid (CSF)</td>\n",
       "      <td>Hematology</td>\n",
       "      <td>26506-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550</td>\n",
       "      <td>51350</td>\n",
       "      <td>Immunophenotyping</td>\n",
       "      <td>Cerebrospinal Fluid (CSF)</td>\n",
       "      <td>Hematology</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>749</td>\n",
       "      <td>51551</td>\n",
       "      <td>VOIDED SPECIMEN</td>\n",
       "      <td>OTHER BODY FLUID</td>\n",
       "      <td>HEMATOLOGY</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>750</td>\n",
       "      <td>51552</td>\n",
       "      <td>VOIDED SPECIMEN</td>\n",
       "      <td>STOOL</td>\n",
       "      <td>CHEMISTRY</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>751</td>\n",
       "      <td>51553</td>\n",
       "      <td>VOIDED SPECIMEN</td>\n",
       "      <td>URINE</td>\n",
       "      <td>CHEMISTRY</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>752</td>\n",
       "      <td>51554</td>\n",
       "      <td>VOIDED SPECIMEN</td>\n",
       "      <td>JOINT FLUID</td>\n",
       "      <td>HEMATOLOGY</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>753</td>\n",
       "      <td>51555</td>\n",
       "      <td>SURFACTANT ALBUMIN RATIO</td>\n",
       "      <td>OTHER BODY FLUID</td>\n",
       "      <td>CHEMISTRY</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>753 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ROW_ID  ITEMID                       LABEL                      FLUID  \\\n",
       "0       546   51346                      Blasts  Cerebrospinal Fluid (CSF)   \n",
       "1       547   51347                 Eosinophils  Cerebrospinal Fluid (CSF)   \n",
       "2       548   51348             Hematocrit, CSF  Cerebrospinal Fluid (CSF)   \n",
       "3       549   51349  Hypersegmented Neutrophils  Cerebrospinal Fluid (CSF)   \n",
       "4       550   51350           Immunophenotyping  Cerebrospinal Fluid (CSF)   \n",
       "..      ...     ...                         ...                        ...   \n",
       "748     749   51551             VOIDED SPECIMEN           OTHER BODY FLUID   \n",
       "749     750   51552             VOIDED SPECIMEN                      STOOL   \n",
       "750     751   51553             VOIDED SPECIMEN                      URINE   \n",
       "751     752   51554             VOIDED SPECIMEN                JOINT FLUID   \n",
       "752     753   51555    SURFACTANT ALBUMIN RATIO           OTHER BODY FLUID   \n",
       "\n",
       "       CATEGORY LOINC_CODE  \n",
       "0    Hematology    26447-3  \n",
       "1    Hematology    26451-5  \n",
       "2    Hematology    30398-2  \n",
       "3    Hematology    26506-6  \n",
       "4    Hematology       None  \n",
       "..          ...        ...  \n",
       "748  HEMATOLOGY       None  \n",
       "749   CHEMISTRY       None  \n",
       "750   CHEMISTRY       None  \n",
       "751  HEMATOLOGY       None  \n",
       "752   CHEMISTRY       None  \n",
       "\n",
       "[753 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Lab Items Data\n",
    "#labitems_df = pd.read_csv('D_LABITEMS.csv')\n",
    "labitems_df = get_df_from_table_from_db(mimiciii, table_name='d_labitems')\n",
    "labitems_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a53f29f-d312-405d-955b-ae988ba0bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with Lab Item data\n",
    "DataFrame = combined_df.merge(labitems_df[['itemid', 'label']], on='itemid', how='left')\n",
    "\n",
    "# Display the resulting DataFrame with selected column\n",
    "DataFrame[['itemid', 'label', 'arf', 'other']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddac3ec-d907-4c81-89e9-d6ad17ff8cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "DataFrame_csv_path = 'Data/DataViz_Project_DataFrame_Govinda.csv'\n",
    "DataFrame.to_csv(DataFrame_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e3f6b6-e3ad-4316-8c1c-7f3a82914c0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bac4b3-759b-4c08-bf42-395b84c0b644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract admission table with designated attributes\n",
    "admission = get_df_from_table_from_db(mimiciii, 'admissions')\n",
    "admission = admission.apply(lambda x: x.astype(str).str.upper())\n",
    "admission.HADM_ID = admission.HADM_ID.astype('int64')\n",
    "admission.SUBJECT_ID = admission.SUBJECT_ID.astype('int64')\n",
    "\n",
    "admission = admission[['HADM_ID','SUBJECT_ID','DIAGNOSIS']]\n",
    "admission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e242b4-08b2-4162-a207-43e522f56b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import json for HADM_ID list of arf diagnosis\n",
    "arf_data = []\n",
    "with open('arf_hadm_ids.json') as json_file:\n",
    "   arf_data = json.load(json_file)\n",
    "admission.loc[admission['HADM_ID'].isin(list(map(int, arf_data)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47184b2e-392d-4755-98e1-d72c8a015121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mark arf as arf, and the rest as other\n",
    "admission['WR_DIAGNOSIS'] = np.full(len(admission),\"Other\")\n",
    "admission.loc[admission['HADM_ID'].isin(list(map(int, arf_data))),'WR_DIAGNOSIS'] = \"ARF\" \n",
    "admission['WR_DIAGNOSIS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9566385f-caaf-4af0-af6c-0c3583122a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the labevents table, which is huge\n",
    "# labevents = get_df_from_table_from_db(mimiciii, 'labevents')\n",
    "# labevents = labevents[~np.isnan(labevents['HADM_ID'])]\n",
    "# labevents.HADM_ID = labevents.HADM_ID.astype('int64')\n",
    "# labevents.to_csv(\"temp_labevent.csv\",index=False)\n",
    "# labevents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fa36e6-222c-4d14-b418-5b42389901de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the labitems table for ITEMID-test name mapping\n",
    "test_names = get_df_from_table_from_db(mimiciii, 'd_labitems')\n",
    "test_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc602e1-c764-4944-8d15-be495eefccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are too many tests types and not all of them are performed for a HADM_ID\n",
    "# So instead, we pick the most common 10 tests to decrease the number of dropped tests when doing dropna \n",
    "most_common_tests = labevents.groupby('ITEMID').count().sort_values(by='HADM_ID', ascending=False)[0:10]\n",
    "most_common_tests = pd.DataFrame({'ITEMID':most_common_tests.index,'COUNT':most_common_tests['HADM_ID']})\n",
    "most_common_tests.reset_index(drop=True,inplace=True)\n",
    "most_common_tests = most_common_tests.merge(test_names,on='ITEMID',how='left')[['ITEMID','LABEL']]\n",
    "most_common_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174019fb-326d-476b-9d5c-e5f12a716d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the labevents according to the most common tests\n",
    "labevents = labevents[labevents['ITEMID'].isin(most_common_tests['ITEMID'].unique())]\n",
    "labevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4e0090-df69-4af7-b7ee-d05433d2c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align two tables\n",
    "labevents = labevents[labevents['HADM_ID'].isin(admission['HADM_ID'].unique())]\n",
    "admission = admission[admission['HADM_ID'].isin(labevents['HADM_ID'].unique())]\n",
    "print(len(labevents['HADM_ID'].unique()))\n",
    "print(len(admission['HADM_ID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b64352-daff-4168-84b8-1b4ec4b523b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make columns for most common tests' values and abnormalities\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for name in most_common_tests['LABEL']:\n",
    "    admission.loc[:,name] = np.full(len(admission),\"\")\n",
    "    admission.loc[:,name+\"_ab\"] = np.full(len(admission),False)\n",
    "admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24ba04d-ddaa-446b-8744-73e21bfe239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect values form labevents and fill them into admission dataframe\n",
    "for id in admission['HADM_ID']:\n",
    "    temp = labevents[labevents['HADM_ID'] == id]\n",
    "    for item in most_common_tests['ITEMID']:\n",
    "        row = admission['HADM_ID'] == id\n",
    "        col = most_common_tests[most_common_tests['ITEMID'] == item]['LABEL'].values[0]\n",
    "        if len(temp[temp['ITEMID'] == item]['VALUE'].values) <= 0:\n",
    "            admission.loc[row, col] = np.NaN\n",
    "            admission.loc[row, col+'_ab'] = np.NaN\n",
    "        else:\n",
    "            admission.loc[row, col] = temp[temp['ITEMID'] == item]['VALUE'].values[0]\n",
    "            admission.loc[row, col+'_ab'] = temp[temp['ITEMID'] == item]['FLAG'].values[0] == \"abnormal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21d411e-a06e-4550-97f3-317be76604d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data for later use\n",
    "admission.to_csv(\"Data/ED_Wrangling_Result.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583cfb3a-bdd4-4dba-9b5d-ae96d6f5ce65",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Kolton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3206d-1f48-4c2b-845f-de74e051f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all noteevents\n",
    "noteevents = get_df_from_table_from_db(mimiciii, 'noteevents')\n",
    "noteevents.HADM_ID = noteevents.HADM_ID.apply(fix_dot_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90464482-f871-4145-bda7-1629a6a765df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#condense/combine all notes associated with single HADM_ID into one note\n",
    "condensed_notes = condense_notes(admission, noteevents)\n",
    "for index, row in condensed_notes.iterrows():\n",
    "    with open(f'all_notes/{row[\"HADM_ID\"]}.txt', 'w') as f:\n",
    "        f.write(row['TEXT'])\n",
    "\n",
    "#save that file\n",
    "condensed_notes.to_csv('Data/all_notes_raw.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
